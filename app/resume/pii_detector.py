from transformers import pipeline
from app.core.regex_utils import detect_regex_pii
from typing import Dict
import logging

NER_LABEL_MAP = {
    "PER": "name",
    "LOC": "location", 
    "ORG": "organization",
    "MISC": "misc"
}

try:
    print("ğŸ“¦ Loading NER model for PII detection...")
    ner = pipeline("ner", model="FacebookAI/xlm-roberta-large-finetuned-conll03-english", aggregation_strategy="simple")
    print("âœ… NER model loaded successfully")
except Exception as e:
    print(f"âŒ Failed to load NER model: {e}")
    ner = None

def detect_pii(text: str, debug: bool = False) -> Dict:
    if ner is None:
        print("âš ï¸ NER model not available, using regex-only PII detection")
        ner_entities = []
    else:
        ner_entities = ner(text)
    regex_result = detect_regex_pii(text)

    ner_result = {}
    for ent in ner_entities:
        raw_label = ent["entity_group"].upper()
        mapped_label = NER_LABEL_MAP.get(raw_label)
        if mapped_label in ["name", "location"]:  # ì›í•˜ëŠ” í•­ëª©ë§Œ í¬í•¨
            ner_result.setdefault(mapped_label, []).append(ent["word"])

    if debug:
        print("\nğŸ“Œ [NER ê²°ê³¼]")
        for label, items in ner_result.items():
            print(f"- {label}: {list(set(items))}")

        print("\nğŸ“Œ [Regex ê²°ê³¼]")
        for label, items in regex_result.items():
            print(f"- {label}: {list(set(items))}")

    masked_text = text

    for label, matches in regex_result.items():
        for match in set(matches):
            match_str = "".join(match) if isinstance(match, tuple) else match
            masked_text = masked_text.replace(match_str, f"[REDACTED_{label.upper()}]")

    for label, words in ner_result.items():
        for word in sorted(set(words), key=len, reverse=True):
            masked_text = masked_text.replace(word, f"[REDACTED_{label.upper()}]")

    detected_labels = set(regex_result.keys()) | set(ner_result.keys())

    return {
        "regex_result": regex_result,
        "ner_result": ner_result,
        "anonymized_text": masked_text,
        "detected_pii_fields": list(detected_labels),
        "deleted_fields": list(detected_labels)
    }

# í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    raw_text = """
    ì„± ëª… ì´ìˆ˜ë¯¼ ì˜ ë¬¸ Lee sumin
    ì—° ë½ ì²˜ 010-0000-0000 ìƒë…„ì›”ì¼ 2001.01.01
    í•™ë ¥ì‚¬í•­: 2017-2019 ê´‘ë‚¨ê³ ë“±í•™êµ ì¡¸ì—…, 2020-2024 í•œì–‘ëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ê³¼ ì¡¸ì—…
    ì„±ì : 3.8/4.5
    ìê²©ì¦: ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ (2023.02.20), ë¹…ë°ì´í„°ë¶„ì„ê¸°ì‚¬ (2021.10.01)
    í™œë™: 2022.10.28 êµë‚´ í•´ì»¤í†¤ ì€ìƒ, 2023.12.12 ë„¤ì´ë²„ AI í•´ì»¤í†¤ ë³¸ì„  ì§„ì¶œ
    """

    result = detect_pii(raw_text, debug=True)

    print("\nğŸ”’ [ìµœì¢… ë§ˆìŠ¤í‚¹ í…ìŠ¤íŠ¸]")
    print(result["anonymized_text"])