from typing import Dict, List, Optional
from datetime import datetime, timedelta
import hashlib
import threading
import asyncio
from contextlib import asynccontextmanager


class QuestionCacheManager:
    """ì§ˆë¬¸ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ë©”ëª¨ë¦¬ ê¸°ë°˜ ìºì‹œ ë§¤ë‹ˆì €"""
    
    def __init__(self, ttl_hours: int = 24, max_questions_per_key: int = 20):
        self._cache: Dict[str, Dict] = {}
        self._lock = threading.Lock()
        self._ttl_hours = ttl_hours
        self._max_questions_per_key = max_questions_per_key
        self._cleanup_task: Optional[asyncio.Task] = None
        self._cleanup_interval_hours = 3  # 3ì‹œê°„ë§ˆë‹¤ ìë™ ì •ë¦¬
    
    def _generate_cache_key(self, document_id: str, job_type: str, 
                           question_category: str, question_level: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„± (MD5 í•´ì‹œ ì‚¬ìš©)"""
        key_string = f"{document_id}:{job_type}:{question_category}:{question_level}"
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def _is_expired(self, cache_entry: Dict) -> bool:
        """ìºì‹œ ì—”íŠ¸ë¦¬ ë§Œë£Œ ì—¬ë¶€ í™•ì¸"""
        return datetime.now() > cache_entry['expires_at']
    
    def get_previous_questions(self, document_id: str, job_type: str,
                              question_category: str, question_level: str) -> List[str]:
        """ì´ì „ì— ìƒì„±ëœ ì§ˆë¬¸ë“¤ ì¡°íšŒ"""
        with self._lock:
            cache_key = self._generate_cache_key(document_id, job_type, question_category, question_level)
            cache_entry = self._cache.get(cache_key)
            
            if not cache_entry or self._is_expired(cache_entry):
                if cache_entry:
                    del self._cache[cache_key]
                return []
            
            return cache_entry['questions'].copy()
    
    def add_question(self, document_id: str, job_type: str,
                     question_category: str, question_level: str, question: str) -> None:
        """ìƒˆ ì§ˆë¬¸ì„ ìºì‹œì— ì¶”ê°€"""
        with self._lock:
            cache_key = self._generate_cache_key(document_id, job_type, question_category, question_level)
            
            # ìƒˆ ìºì‹œ ì—”íŠ¸ë¦¬ ìƒì„± ë˜ëŠ” ê¸°ì¡´ ì—”íŠ¸ë¦¬ ê°€ì ¸ì˜¤ê¸°
            if cache_key not in self._cache:
                self._cache[cache_key] = {
                    'questions': [],
                    'expires_at': datetime.now() + timedelta(hours=self._ttl_hours),
                    'document_id': document_id
                }
            
            # ì§ˆë¬¸ ì¶”ê°€
            self._cache[cache_key]['questions'].append(question)
            
            # ìµœëŒ€ ì§ˆë¬¸ ìˆ˜ ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
            if len(self._cache[cache_key]['questions']) > self._max_questions_per_key:
                self._cache[cache_key]['questions'] = self._cache[cache_key]['questions'][-self._max_questions_per_key:]
    
    def clear_cache_by_document(self, document_id: str) -> int:
        """íŠ¹ì • document_idì˜ ëª¨ë“  ìºì‹œ ì‚­ì œ"""
        with self._lock:
            keys_to_delete = [
                key for key, value in self._cache.items()
                if value.get('document_id') == document_id
            ]
            
            for key in keys_to_delete:
                del self._cache[key]
            
            return len(keys_to_delete)
    
    def cleanup_expired_entries(self) -> int:
        """ë§Œë£Œëœ ìºì‹œ ì—”íŠ¸ë¦¬ë“¤ ì •ë¦¬"""
        with self._lock:
            now = datetime.now()
            expired_keys = [
                key for key, value in self._cache.items()
                if now > value['expires_at']
            ]
            
            for key in expired_keys:
                del self._cache[key]
            
            return len(expired_keys)
    
    def get_cache_stats(self) -> Dict:
        """ìºì‹œ í†µê³„ ì •ë³´ ë°˜í™˜"""
        with self._lock:
            total_entries = len(self._cache)
            total_questions = sum(len(entry['questions']) for entry in self._cache.values())
            
            return {
                'total_cache_entries': total_entries,
                'total_cached_questions': total_questions,
                'ttl_hours': self._ttl_hours,
                'max_questions_per_key': self._max_questions_per_key,
                'cleanup_interval_hours': self._cleanup_interval_hours
            }
    
    async def _periodic_cleanup(self):
        """ì£¼ê¸°ì  ìºì‹œ ì •ë¦¬ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬"""
        while True:
            try:
                await asyncio.sleep(self._cleanup_interval_hours * 3600)  # ì‹œê°„ì„ ì´ˆë¡œ ë³€í™˜
                cleaned_count = self.cleanup_expired_entries()
                if cleaned_count > 0:
                    print(f"ğŸ§¹ ìë™ ìºì‹œ ì •ë¦¬: {cleaned_count}ê°œ ë§Œë£Œëœ í•­ëª© ì‚­ì œë¨")
            except asyncio.CancelledError:
                print("ìºì‹œ ì •ë¦¬ íƒœìŠ¤í¬ ì¤‘ë‹¨ë¨")
                break
            except Exception as e:
                print(f"ìºì‹œ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    async def start_background_cleanup(self):
        """ë°±ê·¸ë¼ìš´ë“œ ìºì‹œ ì •ë¦¬ íƒœìŠ¤í¬ ì‹œì‘"""
        if self._cleanup_task is None or self._cleanup_task.done():
            self._cleanup_task = asyncio.create_task(self._periodic_cleanup())
            print(f"ìºì‹œ ìë™ ì •ë¦¬ íƒœìŠ¤í¬ ì‹œì‘ (ì£¼ê¸°: {self._cleanup_interval_hours}ì‹œê°„)")
    
    async def stop_background_cleanup(self):
        """ë°±ê·¸ë¼ìš´ë“œ ìºì‹œ ì •ë¦¬ íƒœìŠ¤í¬ ì¤‘ë‹¨"""
        if self._cleanup_task and not self._cleanup_task.done():
            self._cleanup_task.cancel()
            try:
                await self._cleanup_task
            except asyncio.CancelledError:
                pass
            print("ğŸ›‘ ìºì‹œ ìë™ ì •ë¦¬ íƒœìŠ¤í¬ ì¤‘ë‹¨ë¨")


# ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
question_cache = QuestionCacheManager()


@asynccontextmanager
async def cache_lifespan(app):
    """FastAPI ì•± ë¼ì´í”„ì‚¬ì´í´ ë§¤ë‹ˆì € - ìºì‹œ ìë™ ì •ë¦¬ íƒœìŠ¤í¬ ê´€ë¦¬"""
    # ì‹œì‘ ì‹œ
    await question_cache.start_background_cleanup()
    yield
    # ì¢…ë£Œ ì‹œ
    await question_cache.stop_background_cleanup() 